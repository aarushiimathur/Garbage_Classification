{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuF-uOhaJRbN"
      },
      "source": [
        "### Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1rOJVe3FXdG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Layer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Rescaling , GlobalAveragePooling2D\n",
        "from tensorflow.keras import layers, optimizers, callbacks\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hfTXhNhJYOp"
      },
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIOLJf7OHpBr",
        "outputId": "8d89264a-688e-4b8f-d7c0-80f191dc59f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2275295361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/content/drive/MyDrive/TrashType_Image_Dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m124\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_dir = r\"/content/drive/MyDrive/TrashType_Image_Dataset\"\n",
        "image_size = (124, 124)\n",
        "batch_size = 32\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lej7VKb5ngFQ"
      },
      "source": [
        "### Understanding the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIQ2DBz0niQq"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    shuffle = True,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz2RHZBHnktS"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    shuffle = True,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "val_class= val_ds.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZgfVVPrnkqp"
      },
      "outputs": [],
      "source": [
        "# Get the total number of batches in the validation dataset\n",
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "\n",
        "# Split the validation dataset into two equal parts:\n",
        "# First half becomes the test dataset\n",
        "test_ds = val_ds.take(val_batches // 2)\n",
        "\n",
        "# Second half remains as the validation dataset\n",
        "val_dat = val_ds.skip(val_batches // 2)\n",
        "\n",
        "# Optimize test dataset by caching and prefetching to improve performance\n",
        "test_ds_eval = test_ds.cache().prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "384_B0kinpTZ"
      },
      "outputs": [],
      "source": [
        "print(train_ds.class_names)\n",
        "print(val_class)\n",
        "print(len(train_ds.class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQs3rh50oaBz"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NZY1kOLodEl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(12):\n",
        "    ax = plt.subplot(4, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(train_ds.class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b17Wqz9NotqE"
      },
      "outputs": [],
      "source": [
        "def count_distribution(dataset, class_names):\n",
        "    total = 0\n",
        "    counts = {name: 0 for name in class_names}\n",
        "\n",
        "    for _, labels in dataset:\n",
        "        for label in labels.numpy():\n",
        "            class_name = class_names[label]\n",
        "            counts[class_name] += 1\n",
        "            total += 1\n",
        "\n",
        "    for k in counts:\n",
        "        counts[k] = round((counts[k] / total) * 100, 2)  # Convert to percentage\n",
        "    return counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyC7d7FQowJQ"
      },
      "outputs": [],
      "source": [
        "# Function to plot class distribution\n",
        "def simple_bar_plot(dist, title):\n",
        "    plt.bar(dist.keys(), dist.values(), color='cornflowerblue')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Percentage (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 100)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZxNSFtyox7a"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "\n",
        "# Get class distributions\n",
        "train_dist = count_distribution(train_ds, class_names)\n",
        "val_dist = count_distribution(val_ds, class_names)\n",
        "test_dist = count_distribution(test_ds, class_names)\n",
        "overall_dist = {}\n",
        "for k in class_names:\n",
        "    overall_dist[k] = round((train_dist[k] + val_dist[k]) / 2, 2)\n",
        "\n",
        "print(train_dist)\n",
        "print(val_dist)\n",
        "print(test_dist)\n",
        "print(overall_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH9xGvecpX4W"
      },
      "outputs": [],
      "source": [
        "simple_bar_plot(train_dist, \"Training Set Class Distribution (%)\")\n",
        "simple_bar_plot(val_dist, \"Validation Set Class Distribution (%)\")\n",
        "simple_bar_plot(test_dist, \"Test Set Class Distribution (%)\")\n",
        "simple_bar_plot(overall_dist, \"Overall Class Distribution (%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y3QoUMRqAca"
      },
      "outputs": [],
      "source": [
        "class_counts = {i: 0 for i in range(len(class_names))}\n",
        "all_labels = []\n",
        "\n",
        "for images, labels in train_ds:\n",
        "    for label in labels.numpy():\n",
        "        class_counts[label] += 1\n",
        "        all_labels.append(label)\n",
        "\n",
        "# Compute class weights (index aligned)\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.arange(len(class_names)),\n",
        "    y=all_labels\n",
        ")\n",
        "\n",
        "# Create dictionary mapping class index to weight\n",
        "class_weights = {i: w for i, w in enumerate(class_weights_array)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWb8OVwNqCX3"
      },
      "outputs": [],
      "source": [
        "print(\"Class Counts:\", class_counts)\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GmHqsbEq0xt"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fzn0zowq3C4"
      },
      "outputs": [],
      "source": [
        "data_augmentation = Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "3xfyEauxal97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 as base model\n",
        "base_model = ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(124, 124, 3),\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "id": "ESvXCKuPWUjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "SBDEEZVYanQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    layers.Input(shape=(124, 124, 3)),\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(6, activation='softmax')  # Change to your number of classes\n",
        "])"
      ],
      "metadata": {
        "id": "0lYGJ-bmliRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "YE99KeQRljm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callback - to stop training when validation score stops improving\n",
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',            # Metric to monitor (validation loss here)\n",
        "    patience=3,                   # Number of epochs to wait after last improvement before stopping\n",
        "    restore_best_weights=True     # After stopping, restore the model weights from the epoch with the best val_loss\n",
        ")"
      ],
      "metadata": {
        "id": "wL6Zfv-DlntD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15  # Number of times the model will go through the entire dataset\n",
        "\n",
        "# Train the model using the fit function\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    batch_size=32,\n",
        "    callbacks=[early]\n",
        ")"
      ],
      "metadata": {
        "id": "ZDYOzbyUlv1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "picS9Engl2OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Performance"
      ],
      "metadata": {
        "id": "Qoa0ymtul6YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']          # Extract training accuracy from history\n",
        "val_acc = history.history['val_accuracy']  # Extract validation accuracy from history\n",
        "loss = history.history['loss']             # Extract training loss from history\n",
        "val_loss = history.history['val_loss']     # Extract validation loss from history\n",
        "\n",
        "epochs_range = range(len(acc))             # Define range for epochs based on accuracy length\n",
        "\n",
        "plt.figure(figsize=(10,8))                 # Set overall figure size for visualization\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training vs Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A40E9SI_mAVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "zp8Ag7DFmOjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_ds_eval)\n",
        "print(f'Test accuracy is{accuracy:.4f}, Test loss is {loss:.4f}')"
      ],
      "metadata": {
        "id": "qfHysXiwmRJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.concatenate([y.numpy() for x, y in test_ds_eval], axis=0)  # Convert Tensor labels to NumPy array and concatenate them\n",
        "y_pred_probs = model.predict(test_ds_eval)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)"
      ],
      "metadata": {
        "id": "08rnehSVmSq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "LOQbBiIHmYDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "mwirQkyLmZ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cmap='Blues')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BJVjKLbTmeEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "lqfg805WmokD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "\n",
        "for images, labels in test_ds_eval.take(1):\n",
        "    predictions = model.predict(images)\n",
        "    pred_labels = tf.argmax(predictions, axis=1)\n",
        "    for i in range(8):\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Convert and display image\n",
        "        plt.title(f\"True: {class_names[labels[i]]}, Pred: {class_names[pred_labels[i]]}\")  # Show actual and predicted class\n",
        "        plt.axis(\"off\")  # Hide axes for better visualization\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "nYnXV8SCmsJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('GarbaageClassification.keras')\n",
        "model = tf.keras.models.load_model('GarbaageClassification.keras')"
      ],
      "metadata": {
        "id": "eWqA5GGRm1Lj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GuF-uOhaJRbN",
        "5hfTXhNhJYOp",
        "lej7VKb5ngFQ",
        "MQs3rh50oaBz",
        "0GmHqsbEq0xt",
        "3xfyEauxal97",
        "Qoa0ymtul6YB",
        "zp8Ag7DFmOjK",
        "lqfg805WmokD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}